{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfwgwECujp2a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "id": "q0mZlAInjuM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .appName('PySpark_Tutorial')\\\n",
        "        .getOrCreate()\n"
      ],
      "metadata": {
        "id": "zhQ7l-eWjwMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "import numpy as np\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "47P6OEf5jwy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=spark.read.csv('heart.csv',inferSchema=True,header=True)\n",
        "     \n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "id": "wiKeNdBejyRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "metadata": {
        "id": "gMxvNrcXj1FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()\n",
        "    "
      ],
      "metadata": {
        "id": "cN0mFd4Kj382"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "3aiFNqTcj3Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Feature Information:\n",
        "\n",
        "1. age: The person’s age in years\n",
        "\n",
        "2. sex: The person’s sex (1 = male, 0 = female)\n",
        "\n",
        "3. cp: The chest pain experienced (0 = typical angina, 1= atypical angina, 2= non-anginal pain, 3 = asymptomatic)\n",
        "\n",
        "4. trestbps: The person’s resting blood pressure (mm Hg on admission to the hospital)\n",
        "\n",
        "5. chol: The person’s cholesterol measurement in mg/dl\n",
        "\n",
        "6. fbs: The person’s fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false).\n",
        "\n",
        "7. restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes’ criteria)\n",
        "\n",
        "8. thalach: The person’s maximum heart rate achieved\n",
        "\n",
        "9. exang: Exercise induced angina (1 = yes; 0 = no)\n",
        "\n",
        "10. oldpeak: ST depression induced by exercise relative to rest\n",
        "\n",
        "11. slope: the slope of the peak exercise ST segment (0 = upsloping, 1 = flat, 2 = downsloping)\n",
        "\n",
        "12. ca: The number of major vessels (0–4)\n",
        "\n",
        "13. thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
        "\n",
        "14. target: Heart disease (0 = no, 1 = yes)\n",
        "\"\"\"\n",
        "     "
      ],
      "metadata": {
        "id": "SRivMAnckAhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,sum\n",
        "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()\n",
        "     \n",
        "\n",
        "data.select('target').show(3)"
      ],
      "metadata": {
        "id": "emTol9X-kBST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_data =data.toPandas()\n",
        "pd_data"
      ],
      "metadata": {
        "id": "Bj80TwwTj8ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('target').count().show()"
      ],
      "metadata": {
        "id": "CLNmXPlYkF7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(pd_data['target'])"
      ],
      "metadata": {
        "id": "KuRbvNOakJNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('sex').count().show()"
      ],
      "metadata": {
        "id": "IZvGFOXokJrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(pd_data['sex'])\n",
        "plt.xticks([0,1],['Female', 'Male'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LIX_ruxwkM3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='sex',hue=\"target\",data=pd_data)\n",
        "plt.xticks([1,0],['Male','Female'])\n",
        "plt.legend(labels = ['No-Disease','Disease'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NJ9q2vq6kO_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "bins= [10,20,30,40,50,60,70,80,90]\n",
        "\n",
        "labels = [2,3,4,5,6,7,8,9]\n",
        "pd_data['AgeGroup'] = pd.cut(pd_data['age'], bins=bins, labels=labels, right=False)"
      ],
      "metadata": {
        "id": "7uCEeB_XkRJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='AgeGroup',hue=\"target\",data=pd_data)\n",
        "plt.legend(labels = ['men No-Disease','men Disease'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3G3tJuEHkVl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='AgeGroup',hue=\"target\",data=pd_data.loc[pd_data['sex']!=1])\n",
        "plt.legend(labels = ['men No-Disease','men Disease'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6UlzH8t1kX54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='AgeGroup',hue=\"target\",data=pd_data.loc[pd_data['sex']!=0])\n",
        "plt.legend(labels = ['women No-Disease','women Disease'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w3zLmyQMkaJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('target','cp').count().show()"
      ],
      "metadata": {
        "id": "jCoKRSb4kcSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,sum\n",
        "data.select(*(sum(col(c).isNull().cast('int')).alias(c) for c in data.columns)).show()"
      ],
      "metadata": {
        "id": "StYBlJQ7kf8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe().show()"
      ],
      "metadata": {
        "id": "z7_98TVJkipn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd_data.groupby('target').count().reset_index()[['target','age']].rename(columns={'age':'counts'})\n",
        "colors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']\n",
        "fig = go.Figure(data=[go.Pie(labels=df.target,\n",
        "                             values=df.counts)])\n",
        "fig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=20, textfont_color='black',\n",
        "                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n",
        "fig.update_layout(title='Heart Disease vs. Absence of Heart Disease', title_x=0.5)"
      ],
      "metadata": {
        "id": "DabwXn8pkk-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = pd_data.corr()\n",
        "fig = go.Figure(data=go.Heatmap(z=corr.values,\n",
        " x=corr.index.values,\n",
        " y=corr.columns.values,\n",
        " text=np.round(corr.values,2),\n",
        " texttemplate='%{text}'))\n",
        "fig.update_layout(title=dict(font=dict(size=20), x=0.5))"
      ],
      "metadata": {
        "id": "UlhEUnLzkoWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "encoder = OneHotEncoder(inputCols=['sex','cp','fbs','restecg','exang','slope','ca','thal'],\n",
        "                           outputCols =['sexVec','cpVec','fbsVec','restecgVec','exangVec','slopeVec','caVec','thalVec'])\n",
        "encoded =  encoder.fit(data).transform(data)\n",
        "data_encoded = encoded.drop('sex','cp','fbs','restecg','exang','slope','ca','thal')\n",
        "data_encoded.show()\n",
        "     "
      ],
      "metadata": {
        "id": "fzhfAHq9krAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols =['age','trestbps','chol','thalach','oldpeak','sexVec','cpVec','fbsVec','restecgVec','exangVec','slopeVec','caVec','thalVec'],\n",
        "                           outputCol=\"features\")\n",
        "assembled= assembler.transform(data_encoded)\n",
        "\n",
        "data_asb =assembled.select(\"features\",\"target\")\n",
        "data_asb.show()"
      ],
      "metadata": {
        "id": "m4Zy0SXxkuA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data_asb.randomSplit([.8,.2],seed=12)"
      ],
      "metadata": {
        "id": "MtWKuQHlkvWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "lr = LogisticRegression(labelCol=\"target\", featuresCol=\"features\", maxIter=10, regParam=0.3, elasticNetParam=0.8,family=\"binomial\")\n",
        "\n",
        "lr_model = lr.fit(train_data)\n",
        "lr_predictions = lr_model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='target',predictionCol='prediction', metricName='accuracy')\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "print('Test Accuracy = ', lr_accuracy)"
      ],
      "metadata": {
        "id": "_6bSP88JkzY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "nb = NaiveBayes(labelCol=\"target\", featuresCol=\"features\",smoothing=1.0, modelType=\"gaussian\")\n",
        "\n",
        "nb_model = nb.fit(train_data)\n",
        "nb_predictions = nb_model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='target',predictionCol='prediction', metricName='accuracy')\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
        "print('Test Accuracy = ', nb_accuracy)"
      ],
      "metadata": {
        "id": "y_HbOEyjk1a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol=\"target\", featuresCol=\"features\")\n",
        "\n",
        "rf_model = rf.fit(train_data)\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='target',predictionCol='prediction', metricName='accuracy')\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
        "print('Test Accuracy = ', rf_accuracy)"
      ],
      "metadata": {
        "id": "aiVMvc7wk3nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "pca = PCA(k=13, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
        "model = pca.fit(data_asb).transform(data_asb)\n",
        "\n",
        "data_pca = model.select(\"pcaFeatures\",\"target\")\n",
        "data_pca.head()"
      ],
      "metadata": {
        "id": "6Rbe_UwQk5P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pcadata, test_pcadata = data_pca.randomSplit([.8,.2],seed=12)"
      ],
      "metadata": {
        "id": "eBF_M7Vqk76G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol=\"target\", featuresCol=\"pcaFeatures\")\n",
        "\n",
        "rf_model = rf.fit(train_pcadata)\n",
        "rf_predictions = rf_model.transform(test_pcadata)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='target',predictionCol='prediction', metricName='accuracy')\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
        "print('Test Accuracy = ', rf_accuracy)"
      ],
      "metadata": {
        "id": "KVfbSdJKk9WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "nb = NaiveBayes(labelCol=\"target\", featuresCol=\"pcaFeatures\",smoothing=1.0, modelType=\"gaussian\")\n",
        "\n",
        "nb_model = nb.fit(train_pcadata)\n",
        "nb_predictions = nb_model.transform(test_pcadata)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='target',predictionCol='prediction', metricName='accuracy')\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
        "print('Test Accuracy = ', nb_accuracy)"
      ],
      "metadata": {
        "id": "9zhiMiRpk_CJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}